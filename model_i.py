# -*- coding: utf-8 -*-
"""Model_I.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gnoHXcHun4Fo4oH15FWgXSpUfzE-boit
"""

import tensorflow as tf
from tensorflow.keras import datasets, layers, models, regularizers
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras.preprocessing import image
import io
from IPython.display import display
from google.colab import output
from sklearn.metrics import confusion_matrix
import seaborn as sns

# Загрузка и предобработка данных
(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()
train_images, test_images = train_images / 255.0, test_images / 255.0

# Определение модели
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)),
    layers.BatchNormalization(),
    layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.2),

    layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),
    layers.BatchNormalization(),
    layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.3),

    layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),
    layers.BatchNormalization(),
    layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.4),

    layers.Flatten(),
    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),
    layers.BatchNormalization(),
    layers.Dropout(0.5),
    layers.Dense(10)
])

# Компиляция модели
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

# Обучение модели
history = model.fit(train_images, train_labels, epochs=20, validation_data=(test_images, test_labels))

# Оценка точности на тестовых данных
test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)
print('\nТочность на тестовых данных:', test_acc)

# Визуализация результатов обучения
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1, len(acc) + 1)

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(epochs, acc, 'bo', label='Точность на обучении')
plt.plot(epochs, val_acc, 'b', label='Точность на валидации')
plt.title('Точность на обучении и валидации')
plt.xlabel('Эпохи')
plt.ylabel('Точность')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(epochs, loss, 'bo', label='Потери на обучении')
plt.plot(epochs, val_loss, 'b', label='Потери на валидации')
plt.title('Потери на обучении и валидации')
plt.xlabel('Эпохи')
plt.ylabel('Потери')
plt.legend()

plt.show()

# Получение прогнозов модели для тестовых изображений
predictions = model.predict(test_images)

# Выбор случайных 10 изображений из тестового набора
indices = np.random.randint(0, len(test_images), size=10)

# Вывод изображений с прогнозами и фактическими метками
plt.figure(figsize=(15, 10))
for i, index in enumerate(indices):
    plt.subplot(2, 5, i + 1)
    plt.imshow(test_images[index], cmap=plt.cm.binary)
    predicted_label = np.argmax(predictions[index])
    actual_label = test_labels[index]
    plt.title(f'Прогноз: {predicted_label}, Ожидание: {actual_label}')
    plt.xlabel('Предсказанный класс')
    plt.ylabel('Фактический класс')
plt.tight_layout()
plt.show()

# Дообучение модели
history_fine = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))

# Визуализация результатов дообучения
acc_fine = history_fine.history['accuracy']
val_acc_fine = history_fine.history['val_accuracy']
loss_fine = history_fine.history['loss']
val_loss_fine = history_fine.history['val_loss']

epochs_fine = range(1, len(acc_fine) + 1)

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(epochs_fine, acc_fine, 'bo', label='Точность на обучении (после дообучения)')
plt.plot(epochs_fine, val_acc_fine, 'b', label='Точность на валидации (после дообучения)')
plt.title('Точность на обучении и валидации (после дообучения)')
plt.xlabel('Эпохи')
plt.ylabel('Точность')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(epochs_fine, loss_fine, 'bo', label='Потери на обучении (после дообучения)')
plt.plot(epochs_fine, val_loss_fine, 'b', label='Потери на валидации (после дообучения)')
plt.title('Потери на обучении и валидации (после дообучения)')
plt.xlabel('Эпохи')
plt.ylabel('Потери')
plt.legend()

plt.show()

# Получение прогнозов модели для тестовых изображений
predictions = np.argmax(model.predict(test_images), axis=1)

# Построение матрицы ошибок
cm = confusion_matrix(test_labels, predictions)

# Визуализация матрицы ошибок
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(10), yticklabels=range(10))
plt.xlabel('Прогнозируемый класс')
plt.ylabel('Фактический класс')
plt.title('Матрица ошибок')
plt.show()

# Определение весов классов
class_weights = {0: 1, 1: 1, 2: 2, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 2, 9: 1}

# Компиляция модели с учетом весов классов
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'],
              sample_weight_mode='temporal')

# Дообучение модели с учетом весов классов
history_fine = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels), class_weight=class_weights)

# Дообучение модели на дополнительных 20 эпохах с учетом весов классов
history_fine = model.fit(train_images, train_labels, epochs=20, validation_data=(test_images, test_labels), class_weight=class_weights)

# Вывод точности после дообучения
plt.plot(history_fine.history['accuracy'], label='Точность на обучении')
plt.plot(history_fine.history['val_accuracy'], label = 'Точность на валидации')
plt.xlabel('Эпохи')
plt.ylabel('Точность')
plt.ylim([0, 1])
plt.legend(loc='lower right')
plt.show()

# Вывод потерь после дообучения
plt.plot(history_fine.history['loss'], label='Потери на обучении')
plt.plot(history_fine.history['val_loss'], label = 'Потери на валидации')
plt.xlabel('Эпохи')
plt.ylabel('Потери')
plt.legend(loc='upper right')
plt.show()

# Получение прогнозов модели для тестовых изображений
predictions = model.predict(test_images[:10])

# Вывод изображений с прогнозами и фактическими метками
plt.figure(figsize=(15, 10))
for i in range(10):
    plt.subplot(2, 5, i + 1)
    plt.imshow(test_images[i], cmap=plt.cm.binary)
    predicted_label = np.argmax(predictions[i])
    actual_label = test_labels[i]
    plt.title(f'Прогноз: {predicted_label}, Ожидание: {actual_label}')
    plt.xlabel('Предсказанный класс')
    plt.ylabel('Фактический класс')
plt.tight_layout()
plt.show()

def predict_image_class_from_file(file, model):
    # Преобразование файла в изображение
    img = image.load_img(file, target_size=(32, 32))
    # Преобразование изображения в массив numpy
    img_array = image.img_to_array(img)
    # Нормализация изображения
    img_array = img_array / 255.0
    # Добавление дополнительной размерности
    img_array = np.expand_dims(img_array, axis=0)
    # Получение прогноза от модели
    prediction = model.predict(img_array)
    # Получение индекса предсказанного класса
    predicted_class_index = np.argmax(prediction)
    # Преобразование индекса в строковое представление
    class_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']
    predicted_class = class_labels[predicted_class_index]
    # Вывод предсказанного класса
    print(f"Прогноз: {predicted_class}")